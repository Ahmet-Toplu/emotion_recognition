{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Recognition using a CNN model with integrated heatmap/prioritised convolution operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries I will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    Handles loading, preprocessing, and splitting the FER2013 dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_path=\"fer2013_data\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_data = None\n",
    "        self.train_labels = None\n",
    "        self.val_data = None\n",
    "        self.val_labels = None\n",
    "        self.test_data = None\n",
    "        self.test_labels = None\n",
    "\n",
    "    def load_data_from_folder(self, folder_path):\n",
    "        \"\"\"\n",
    "        Load images and their corresponding labels from a folder structure.\n",
    "        Each subfolder name is treated as the label.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for label, emotion_dir in enumerate(os.listdir(folder_path)):\n",
    "            emotion_folder = os.path.join(folder_path, emotion_dir)\n",
    "\n",
    "            if os.path.isdir(emotion_folder):\n",
    "                for image_file in os.listdir(emotion_folder):\n",
    "                    image_path = os.path.join(emotion_folder, image_file)\n",
    "\n",
    "                    try:\n",
    "                        # Load the image and convert it to an array\n",
    "                        img = load_img(image_path, target_size=(48, 48), color_mode=\"grayscale\")\n",
    "                        img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "                        data.append(img_array)\n",
    "                        labels.append(label)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {image_path}: {e}\")\n",
    "\n",
    "        return np.array(data), np.array(labels)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        Preprocess the data: load train/test folders and split train into train/validation sets.\n",
    "        \"\"\"\n",
    "        # Load train and test data\n",
    "        train_folder = os.path.join(self.dataset_path, \"train\")\n",
    "        test_folder = os.path.join(self.dataset_path, \"test\")\n",
    "\n",
    "        train_data, train_labels = self.load_data_from_folder(train_folder)\n",
    "        test_data, test_labels = self.load_data_from_folder(test_folder)\n",
    "\n",
    "        # Split train data into train/validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Convert labels to one-hot encoding\n",
    "        num_classes = len(np.unique(train_labels))\n",
    "        y_train = to_categorical(y_train, num_classes)\n",
    "        y_val = to_categorical(y_val, num_classes)\n",
    "        y_test = to_categorical(test_labels, num_classes)\n",
    "\n",
    "        self.train_data, self.train_labels = X_train, y_train\n",
    "        self.val_data, self.val_labels = X_val, y_val\n",
    "        self.test_data, self.test_labels = test_data, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionCNN:\n",
    "    \"\"\"\n",
    "    Defines the CNN model for emotion detection and handles training and evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=self.input_shape),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dense(self.num_classes, activation=\"softmax\"),\n",
    "        ])\n",
    "\n",
    "    def compile_model(self):\n",
    "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    def train_model(self, train_data, train_labels, val_data, val_labels, epochs):\n",
    "        self.model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=epochs)\n",
    "\n",
    "    def evaluate_model(self, test_data, test_labels):\n",
    "        loss, accuracy = self.model.evaluate(test_data, test_labels)\n",
    "        print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "        return accuracy\n",
    "\n",
    "    def predict_emotion(self, input_image):\n",
    "        prediction = self.model.predict(np.expand_dims(input_image, axis=0))\n",
    "        return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatmapGenerator:\n",
    "    \"\"\"\n",
    "    Generates and visualizes heatmaps using Class Activation Maps (CAMs).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def compute_gradients(self, input_image, predicted_class):\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [self.model.inputs], [self.model.get_layer(index=-2).output, self.model.output]\n",
    "        )\n",
    "        with tf.GradientTape() as tape:\n",
    "            conv_outputs, predictions = grad_model(np.expand_dims(input_image, axis=0))\n",
    "            loss = predictions[:, predicted_class]\n",
    "        grads = tape.gradient(loss, conv_outputs)\n",
    "        return conv_outputs, grads\n",
    "\n",
    "    def generate_heatmap(self, conv_outputs, grads):\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "        heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs[0]), axis=-1)\n",
    "        heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "        return heatmap\n",
    "\n",
    "    def visualize_heatmap(self, input_image, heatmap):\n",
    "        plt.imshow(input_image.squeeze(), cmap=\"gray\")\n",
    "        plt.imshow(heatmap, cmap=\"jet\", alpha=0.5)\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class EmotionDetectionSystem:\n",
    "    \"\"\"\n",
    "    Main class that orchestrates the entire process: preprocessing, training, and heatmap generation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_path, input_shape, num_classes):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.data_preprocessor = DataPreprocessor(dataset_path)\n",
    "        self.emotion_cnn = EmotionCNN(input_shape, num_classes)\n",
    "        self.heatmap_generator = None\n",
    "\n",
    "    def run(self):\n",
    "        # Load and preprocess the dataset\n",
    "        self.data_preprocessor.preprocess_data()\n",
    "\n",
    "        # Build, compile, and train the CNN model\n",
    "        self.emotion_cnn.build_model()\n",
    "        self.emotion_cnn.compile_model()\n",
    "        self.emotion_cnn.train_model(\n",
    "            self.data_preprocessor.train_data,\n",
    "            self.data_preprocessor.train_labels,\n",
    "            self.data_preprocessor.val_data,\n",
    "            self.data_preprocessor.val_labels,\n",
    "            epochs=10,\n",
    "        )\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        self.emotion_cnn.evaluate_model(self.data_preprocessor.test_data, self.data_preprocessor.test_labels)\n",
    "\n",
    "        # Generate and visualize heatmaps\n",
    "        self.heatmap_generator = HeatmapGenerator(self.emotion_cnn.model)\n",
    "        for i in range(3):  # Visualize for first 3 test samples\n",
    "            input_image = self.data_preprocessor.test_data[i]\n",
    "            predicted_class = self.emotion_cnn.predict_emotion(input_image)\n",
    "            conv_outputs, grads = self.heatmap_generator.compute_gradients(input_image, predicted_class)\n",
    "            heatmap = self.heatmap_generator.generate_heatmap(conv_outputs, grads)\n",
    "            self.heatmap_generator.visualize_heatmap(input_image, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# Run the system\n",
    "dataset_path = \"fer2013_data\"\n",
    "input_shape = (48, 48, 1)\n",
    "num_classes = 7\n",
    "emotion_system = EmotionDetectionSystem(dataset_path, input_shape, num_classes)\n",
    "emotion_system.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

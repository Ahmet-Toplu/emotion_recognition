{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Recognition using a CNN model with integrated heatmap/prioritised convolution operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries I will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define emotion labels\n",
    "EMOTION_LABELS = [\n",
    "    \"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"\n",
    "]\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessor\n",
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    Handles loading, preprocessing, and splitting the FER2013 dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_path=\"fer2013_data\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_data = None\n",
    "        self.train_labels = None\n",
    "        self.val_data = None\n",
    "        self.val_labels = None\n",
    "        self.test_data = None\n",
    "        self.test_labels = None\n",
    "\n",
    "    def load_data_from_folder(self, folder_path):\n",
    "        \"\"\"\n",
    "        Load images and their corresponding labels from a folder structure.\n",
    "        Each subfolder name is treated as the label.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for label, emotion_dir in enumerate(os.listdir(folder_path)):\n",
    "            emotion_folder = os.path.join(folder_path, emotion_dir)\n",
    "\n",
    "            if os.path.isdir(emotion_folder):\n",
    "                for image_file in os.listdir(emotion_folder):\n",
    "                    image_path = os.path.join(emotion_folder, image_file)\n",
    "\n",
    "                    try:\n",
    "                        # Load the image and convert it to an array\n",
    "                        img = load_img(image_path, target_size=(48, 48), color_mode=\"grayscale\")\n",
    "                        img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "                        data.append(img_array)\n",
    "                        labels.append(label)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {image_path}: {e}\")\n",
    "\n",
    "        return np.array(data), np.array(labels)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        Preprocess the data: load train/test folders and split train into train/validation sets.\n",
    "        \"\"\"\n",
    "        # Load train and test data\n",
    "        train_folder = os.path.join(self.dataset_path, \"train\")\n",
    "        test_folder = os.path.join(self.dataset_path, \"test\")\n",
    "\n",
    "        train_data, train_labels = self.load_data_from_folder(train_folder)\n",
    "        test_data, test_labels = self.load_data_from_folder(test_folder)\n",
    "\n",
    "        # Display a sample image and its label\n",
    "        self.display_sample(train_data, train_labels, \"Train\")\n",
    "\n",
    "        # Split train data into train/validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Convert labels to one-hot encoding\n",
    "        num_classes = len(np.unique(train_labels))\n",
    "        y_train = to_categorical(y_train, num_classes)\n",
    "        y_val = to_categorical(y_val, num_classes)\n",
    "        y_test = to_categorical(test_labels, num_classes)\n",
    "\n",
    "        self.train_data, self.train_labels = X_train, y_train\n",
    "        self.val_data, self.val_labels = X_val, y_val\n",
    "        self.test_data, self.test_labels = test_data, y_test\n",
    "\n",
    "    def display_sample(self, data, labels, dataset_name=\"Dataset\"):\n",
    "        \"\"\"\n",
    "        Display a random sample image and its corresponding label.\n",
    "        \"\"\"\n",
    "        index = np.random.randint(len(data))\n",
    "        sample_image = data[index]\n",
    "        sample_label = labels[index]\n",
    "\n",
    "        plt.imshow(sample_image.squeeze(), cmap=\"gray\")\n",
    "        plt.title(f\"{dataset_name} Sample - Label: {EMOTION_LABELS[np.argmax(sample_label)]}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "dataset_path = \"fer2013_data\"\n",
    "preprocessor = DataPreprocessor(dataset_path)\n",
    "preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Convolutional Layer\n",
    "class SpiralConv2D(layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom convolutional layer that applies a kernel in a spiral pattern.\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, kernel_size, activation=None, **kwargs):\n",
    "        super(SpiralConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = layers.Activation(activation) if activation else None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Initialize the kernel and bias for the convolution\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True,\n",
    "            name=\"kernel\"\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.filters,),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=\"bias\"\n",
    "        )\n",
    "\n",
    "        # Precompute spiral indices for the input dimensions\n",
    "        height, width = input_shape[1], input_shape[2]\n",
    "        self.spiral_indices = tf.constant(self.generate_spiral_indices(height, width), dtype=tf.int32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=inputs,\n",
    "            sizes=[1, self.kernel_size, self.kernel_size, 1],\n",
    "            strides=[1, 1, 1, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        print(f\"Patches shape: {patches.shape}\")\n",
    "\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        height, width = tf.shape(inputs)[1], tf.shape(inputs)[2]\n",
    "        depth = tf.shape(inputs)[-1]\n",
    "\n",
    "        patches = tf.reshape(patches, [batch_size, height * width, self.kernel_size, self.kernel_size, depth])\n",
    "        print(f\"Reshaped patches shape: {patches.shape}\")\n",
    "\n",
    "        spiral_patches = tf.gather(patches, self.spiral_indices, axis=1)\n",
    "        print(f\"Spiral patches shape: {spiral_patches.shape}\")\n",
    "\n",
    "        conv_result = tf.einsum(\"bijlm,klmn->bijn\", spiral_patches, self.kernel)\n",
    "        print(f\"Convolution result shape: {conv_result.shape}\")\n",
    "\n",
    "        conv_result = tf.nn.bias_add(conv_result, self.bias)\n",
    "\n",
    "        if self.activation:\n",
    "            conv_result = self.activation(conv_result)\n",
    "\n",
    "        outputs = tf.reshape(conv_result, [batch_size, height, width, self.filters])\n",
    "        return outputs\n",
    "\n",
    "    def generate_spiral_indices(self, height, width):\n",
    "        spiral_indices = []\n",
    "        visited = np.zeros((height, width), dtype=bool)\n",
    "        directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]  # Right, Down, Left, Up\n",
    "        x, y, direction_idx = 0, 0, 0\n",
    "\n",
    "        for _ in range(height * width):\n",
    "            if 0 <= x < height and 0 <= y < width and not visited[x, y]:\n",
    "                spiral_indices.append(x * width + y)  # Flattened index\n",
    "                visited[x, y] = True\n",
    "            else:\n",
    "                # Reverse the last step and change direction\n",
    "                x -= directions[direction_idx][0]\n",
    "                y -= directions[direction_idx][1]\n",
    "                direction_idx = (direction_idx + 1) % 4\n",
    "\n",
    "            x += directions[direction_idx][0]\n",
    "            y += directions[direction_idx][1]\n",
    "\n",
    "        return spiral_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EmotionCNN class\n",
    "class EmotionCNN:\n",
    "    \"\"\"\n",
    "    Defines the CNN model for emotion detection and handles training, evaluation, and saving/loading of the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        # Ensure input_shape is passed correctly to the first layer\n",
    "        self.model = models.Sequential([\n",
    "            SpiralConv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=self.input_shape),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            SpiralConv2D(filters=64, kernel_size=3, activation=\"relu\"),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            SpiralConv2D(filters=128, kernel_size=3, activation=\"relu\"),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dense(self.num_classes, activation=\"softmax\"),\n",
    "        ])\n",
    "\n",
    "        # Print layer names and output shapes for debugging\n",
    "        print(\"Model layers and output shapes:\")\n",
    "        for layer in self.model.layers:\n",
    "            print(f\"Layer Name: {layer.name}, Output Shape: {layer.output_shape}\")\n",
    "\n",
    "    def compile_model(self):\n",
    "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    def train_model(self, train_data, train_labels, val_data, val_labels, epochs):\n",
    "        history = self.model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=epochs)\n",
    "        return history\n",
    "\n",
    "    def evaluate_model(self, test_data, test_labels):\n",
    "        loss, accuracy = self.model.evaluate(test_data, test_labels)\n",
    "        print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "        return accuracy\n",
    "\n",
    "    def predict_emotion(self, input_image):\n",
    "        prediction = self.model.predict(np.expand_dims(input_image, axis=0))\n",
    "        return np.argmax(prediction)\n",
    "\n",
    "    def save_model(self, file_path):\n",
    "        \"\"\"Save the trained model to the specified file path.\"\"\"\n",
    "        if self.model:\n",
    "            self.model.save(file_path)\n",
    "            print(f\"Model saved to {file_path}\")\n",
    "        else:\n",
    "            print(\"Model has not been built or trained yet.\")\n",
    "\n",
    "    def load_model(self, file_path):\n",
    "        \"\"\"Load a trained model from the specified file path.\"\"\"\n",
    "        self.model = models.load_model(file_path)\n",
    "        print(f\"Model loaded from {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap generation\n",
    "class HeatmapGenerator:\n",
    "    \"\"\"\n",
    "    Generates and visualizes heatmaps using Class Activation Maps (CAMs).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def compute_gradients(self, input_image, predicted_class):\n",
    "        # Use the index of the last convolutional layer (-4 in this case)\n",
    "        last_conv_layer = self.model.layers[-4]  # Adjust the index if the model changes\n",
    "\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [self.model.inputs], [last_conv_layer.output, self.model.output]\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            conv_outputs, predictions = grad_model(np.expand_dims(input_image, axis=0))\n",
    "            loss = predictions[:, predicted_class]\n",
    "\n",
    "        grads = tape.gradient(loss, conv_outputs)\n",
    "        return conv_outputs, grads\n",
    "\n",
    "    def generate_heatmap(self, conv_outputs, grads):\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "        conv_outputs = conv_outputs[0]  # Remove batch dimension\n",
    "        heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "        heatmap = np.maximum(heatmap, 0)  # Set negative values to 0\n",
    "        if np.max(heatmap) > 0:\n",
    "            heatmap /= np.max(heatmap)  # Normalize to range [0, 1]\n",
    "        return heatmap\n",
    "\n",
    "    def visualize_heatmap(self, input_image, heatmap, predicted_label, true_label):\n",
    "        \"\"\"\n",
    "        Overlay the heatmap on the input image with a blue-to-red colormap.\n",
    "        \"\"\"\n",
    "        # Normalize heatmap for the color range\n",
    "        norm = Normalize(vmin=0, vmax=1)\n",
    "        \n",
    "        # Create a figure\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "        # Show the input image\n",
    "        ax[0].imshow(input_image.squeeze(), cmap=\"gray\")\n",
    "        ax[0].set_title(f\"Input Image\\nTrue Label: {true_label}\\nPredicted: {predicted_label}\")\n",
    "        ax[0].axis(\"off\")\n",
    "\n",
    "        # Overlay the heatmap\n",
    "        heatmap_colored = plt.cm.coolwarm(norm(heatmap))  # Use the blue-to-red colormap\n",
    "        ax[1].imshow(input_image.squeeze(), cmap=\"gray\")\n",
    "        ax[1].imshow(heatmap_colored, alpha=0.5)  # Overlay with transparency\n",
    "        ax[1].set_title(\"Heatmap Overlay\")\n",
    "        ax[1].axis(\"off\")\n",
    "\n",
    "        plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=\"coolwarm\"), ax=ax[1], orientation=\"vertical\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion detection system\n",
    "class EmotionDetectionSystem:\n",
    "    \"\"\"\n",
    "    Main class that orchestrates the entire process: preprocessing, training, and heatmap generation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_path, input_shape, num_classes, model_path=\"models/emotion_custom_cnn.h5\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model_path = model_path\n",
    "        self.data_preprocessor = DataPreprocessor(dataset_path)\n",
    "        self.emotion_cnn = EmotionCNN(input_shape, num_classes)\n",
    "        self.heatmap_generator = None\n",
    "\n",
    "    def run(self):\n",
    "        # Load and preprocess the dataset\n",
    "        self.data_preprocessor.preprocess_data()\n",
    "\n",
    "        # Check if the model exists at the specified path\n",
    "        if os.path.exists(self.model_path):\n",
    "            # Load the pre-trained model\n",
    "            print(f\"Loading saved model from {self.model_path}...\")\n",
    "            self.emotion_cnn.load_model(self.model_path)\n",
    "        else:\n",
    "            # Create and train a new model if it doesn't exist\n",
    "            print(f\"No model found at {self.model_path}. Creating and training a new model...\")\n",
    "            self.emotion_cnn.build_model()\n",
    "            self.emotion_cnn.compile_model()\n",
    "            self.emotion_cnn.train_model(\n",
    "                self.data_preprocessor.train_data,\n",
    "                self.data_preprocessor.train_labels,\n",
    "                self.data_preprocessor.val_data,\n",
    "                self.data_preprocessor.val_labels,\n",
    "                epochs=10,\n",
    "            )\n",
    "            # Save the trained model\n",
    "            self.emotion_cnn.save_model(self.model_path)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        print(\"Evaluating the model on the test dataset...\")\n",
    "        if hasattr(self.data_preprocessor, \"test_data\"):\n",
    "            self.emotion_cnn.evaluate_model(self.data_preprocessor.test_data, self.data_preprocessor.test_labels)\n",
    "\n",
    "        # Generate and visualize heatmaps\n",
    "        print(\"Generating and visualizing heatmaps...\")\n",
    "        self.heatmap_generator = HeatmapGenerator(self.emotion_cnn.model)\n",
    "        for i in range(3):  # Visualize for the first 3 test samples\n",
    "            input_image = self.data_preprocessor.test_data[i]\n",
    "            true_label = np.argmax(self.data_preprocessor.test_labels[i])  # True label\n",
    "            predicted_class = self.emotion_cnn.predict_emotion(input_image)\n",
    "\n",
    "            conv_outputs, grads = self.heatmap_generator.compute_gradients(input_image, predicted_class)\n",
    "            heatmap = self.heatmap_generator.generate_heatmap(conv_outputs, grads)\n",
    "\n",
    "            self.heatmap_generator.visualize_heatmap(\n",
    "                input_image, heatmap, predicted_label=predicted_class, true_label=true_label\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGZCAYAAABmNy2oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuVElEQVR4nO3deXTX9ZX/8SugLGFLJJF9EYHi3rJonQEKtaJIy3EFNB3r4LgMPcdz6tEpLofjuHRaK91G69gWqp12RmuxAu3oWAtapaCilE1ICwQkoISEkJCNgO/fH528f0b43NcX3olMO8/HOd9zSm7en/3zvf2Ye9+fE8wsGAAAZtbueG8AAOB/D5ICACAiKQAAIpICACAiKQAAIpICACAiKQAAIpICACAiKQAAIpJCohBCTp8JEyYkrWfu3LkWQus2nxcUFNiDDz5o69evt/3791tVVZW988479uSTT9pZZ53VqutqbRMmTGiV43qsFixYYDU1Na2yrOZ9ueKKK1pleR9eZmscn4cffthCCLZ48eJW2DL8b9fheG/AX7rzzz+/xb/vuecemzhxok2aNKnFzzds2JC0nh/+8If2/PPPJy3jw/Ly8mzFihXWtWtXe+ihh+wPf/iDde7c2YYPH26XX365nXvuubZ27dpWWx/+MnXo0MGKi4vNzOziiy+2vn372s6dO4/zVqEtkRQSrVy5ssW/y8vL7YMPPjjs5x/VuXNnq6+vz3k9ZWVlVlZWdkzbeCRXXXWVDRs2zCZOnGjLli2LP//Vr35l3/rWt+yEE05otXXhL9e0adOsqKjIlixZYlOnTrXrrrvOvva1rx2XbenQoYOFEOzQoUPHZf3/V/Cfjz4GS5cutbVr19q4cePstddes9raWps/f76ZmV199dX2wgsv2M6dO62urs42bNhgX/va16xLly4tlnGk/3y0detWW7x4sU2ePNlWrVpldXV19s4779j1118vt+nkk082M7Ndu3YdMf7hdQ0dOtTmz59vJSUlVltbazt27LBFixbZmWee2WJM83+ymDlzpv3Lv/yL7dy502pqamzRokVWVFRkXbt2tX/7t3+z8vJyKy8vt/nz51teXt5h6/3e975nN954o23atMkaGhps/fr1Nn36dLlPZmajRo2y5557zioqKqy+vt7eeustu+qqq3Ia29pyPW7NOnXqZA8//LDt2rXL6urqbNmyZXbuuece9nsf5z7OmjXLGhsb7frrr7ft27cf8dpqPu8zZsyw+++/38rKymzfvn324osv2vDhww/7/Tlz5lhpaanV19fbG2+8YRdeeKEtXbrUli5detgyi4uL7Zvf/Kbt2LHDGhsb7bTTTrOmpib76le/ethyx40bZyEEu/LKK1v3IPwfFPi03mfBggWhpqamxc+WLl0a9uzZE7Zt2xZmz54dJkyYEMaNGxfMLNx1113h1ltvDZdcckkYP358uPHGG8PmzZvDSy+91GIZc+fODeHP39Txs3Xr1rB9+/awbt26UFxcHD73uc+Fp556KoQQ4vKzPhdccEEIIYSVK1eGadOmhYKCgszfHTduXHjooYfC5ZdfHsaNGxemTZsWFi5cGGpra8Pw4cPj702YMCGEEMLWrVvD/Pnzw0UXXRRuvPHGUF1dHV566aXwwgsvhG984xvhwgsvDLfffntoamoK3/nOd1qsK4QQtm3bFtatWxemT58epk6dGn7961+HEEK44oorDlvXhAkT4s8+85nPhIaGhvDyyy+Hq666Klx00UVh/vz5IYQQrrvuujY/z6nHbdu2beHZZ58Nl156abjmmmtCSUlJqKqqCkOGDDnqfTzS8Rk0aFAIIYQFCxbktI/9+vULBw8eDE899VQws/DP//zPIYQQxo8f3+L3mte1ZcuW8JOf/CRccsklYfr06aG0tDRs2rQptGvXLv7uAw88EEII4bHHHgsXXXRRmDVrVigtLQ1lZWVh6dKlhy3z3XffDU8//XSYOnVqmDJlSsjPzw+/+MUvQmlpaYvlmll46qmnwo4dO0L79u2P+/fAX/jnuG/AX9UnKymEEMLEiRPl+Pbt24dx48aFEEI466yz4s+zkkJdXV0YMGBA/FnHjh3Dnj17wve//325rrvvvjs0NDSEZps3bw6PPvpoi/Ue6dOuXbvQoUOHsGnTpvDwww/HnzffyM8991yL3583b14IIYRvf/vbLX6+cOHCsGfPnhY/CyGE2traUFRU1GJ9GzZsCCUlJYet68Nfehs2bAirVq067Eth0aJFoaysLJxwwgltep7VRx23N998s8XvDxw4MDQ2NobHH3/8qPfxSMdn4MCBoampKfzwhz/MaXvvvvvuEEIIF110UTCzMHjw4HDo0KHwxBNPtPi95nUtWbKkxc+vvPLKEEII5513XjCz0LNnz1BfXx/+4z/+o8XvnXfeeSGEcMSksGzZssO2qzk2bdq0+LM+ffqEAwcOhHvuuafVzvH/1Q//+ehjUllZ2eLxuNmQIUPspz/9qe3atcsOHTpkBw8etFdeecXMzEaOHCmXu3r1anv33XfjvxsbG62kpMQGDRokx95///02cOBAu/766+2xxx6z/fv32y233GKrVq2yGTNmxN9r3769zZkzx9avX2+NjY126NAha2pqsuHDhx9xG5csWdLi3++8846Z/fnvFR/9+cknn3zYf0J66aWXbPfu3fHfH3zwgT311FM2bNgw69ev3xH3ZejQoTZy5Ej76U9/Gre5+fPrX//a+vbtayNGjMg8Fu3atWsxpjX+pnK0x+1nP/tZi39v377dli9fbhMnTmyVfdy+fbudeOKJdsMNN+S0/c3/yejFF180M7PS0lJbtmyZXXHFFdatW7fDfn/RokUt/r1mzRozs3gtnn/++dapUyd7+umnW/zeypUrbevWrUfchl/84heH/ezll1+21atX2+zZs+PPbr75Zgsh2OOPP57TviEbSeFjcqT/dp+Xl2e/+93v7LzzzrO7777bPvOZz9jo0aPtsssuM7M//zFaqaioOOxnjY2NOY01M9u9e7f9+Mc/tltuucXOOeccGz9+vB04cMC+853vxN+ZN2+e3XffffbLX/7SPv/5z9vYsWNt9OjRtnr16iOup7KyssW/Dxw44P68U6dOLX7+3nvvHbbM5p81/y3ko0455RQz+3P55MGDB1t8vv/975uZWa9evTKPw0svvdRiTPPffFIc7XHL2u/mfU7dx6MxadIkO/XUU+3nP/+5de/e3Xr06GE9evSwp59+2vLy8mzmzJmHjfnotdjY2Ghm//86bt6P999//7CxR/qZWfbfvL773e/aZz/7WRs+fLh16NDB/uEf/sGeeeaZzOUgd1QffUw++kdisz/feP369bMJEybEpwMzs549e36MW9bS7373O/vv//5vu+yyy6ywsNDKy8utuLjYnnzySbvrrrta/G6vXr2sqqqq1behd+/emT87UhI0M9uzZ4+ZmT344IO2cOHCI/7Opk2bMtd50003tfh/v83LS3G0xy1rv5v3OXUfj8asWbPMzOy2226z22677Yjxo/1/5c370ZzcPqx3795WWlp62M+PdN+Y/fmp6utf/7rNnj3bVqxYYX369LFHHnnkqLYHR0ZSOI6aL/jm/0fV7KabbmrzdRcVFVl5eflhN127du1s2LBhVltbG7+4QgiHbeOUKVOsf//+9qc//anVt+2zn/2sFRUVxf+E1K5dO5s+fbr96U9/yizLLSkpsZKSEjvnnHMO+xLORUlJSdI2H8nRHreZM2favHnz4r8HDhxoF1xwgT355JNxG1P2MVc9e/a0yy67zF599VW7++67D4vfcMMNVlxcbGeccYatX78+5+WuXLnSGhoabPr06fbss8/Gn5933nk2ePDgIyaFLI2Njfb444/bl7/8Zbvgggvs7bfftuXLl+c8HtlICsfR8uXLrbKy0h577DG79957rampya699lo755xz2nzdX/ziF+2mm26yn/3sZ/bGG2/Yvn37rH///nbDDTfYmWeeGbfH7M9/I/jSl75kGzdutDVr1tioUaPs9ttvb/G3jNa0Z88e++1vf2v33Xef1dbW2j/+4z/ayJEjZVnqTTfdZP/1X/9lzz//vP34xz+2srIyKygosJEjR9qnPvUpu/rqq1t1O9u3b3/ELuTa2lp7/vnnj/q4FRUV2bPPPms/+MEPrEePHnbvvfdaQ0NDi76AlH0cOHCgbd682Z544gn37wrXXnutde7c2b773e/ayy+/fFi8oqLCiouLbdasWfaVr3zFO0Qt7N271+bNm2d33nmn7d2715599lnr37+/zZ0713bu3GkffPBBzssyM3v00UftjjvusNGjR8cnG6QjKRxHlZWVdumll9rDDz9s//7v/261tbX23HPP2fTp0+3tt99u03X/6le/st69e9uUKVPslltusfz8fKupqbE1a9ZYcXFx/GOmmdmtt95qTU1NNmfOHOvatau99dZbdvnll9v999/fJtu2aNEiW79+ffxD+ObNm+2aa6457A+UH7Vs2TIbO3as3XXXXfbtb3/b8vPzraKiwjZs2CDHHovOnTvbM888c9jPS0tLbciQIUd93O68804bM2aMLViwwLp3726vv/66zZgxw7Zs2dIq+3jCCSdYhw4drH379u7vzZo1y95//3375S9/ecT4unXr7Pe//70VFxfbP/3TP7nL+qi77rrLamtr7eabb7brr7/eNm7caLfccos98MADR/2fInfu3GmvvvqqnX322Yf9kR5pjnsJFB8+zZ8QQvje97533LeDz8f3GTx4cGhoaAhz5sw5qnGFhYWhrq4ufP3rXz/u+/DX9OFJAcDH5uyzz7aZM2fa8uXLrbq62kaMGGF33HGHVVdX249+9KOcltGvXz879dRT7fbbb7cPPvigRaUcWsdxz0x8+DR/eFL46/4MHTo0vPjii2H37t3hwIEDoby8PPz85z9v0eGtPnPnzg2HDh0KmzdvbtHAxqd1Pif8z/8AAIDmNQDA/0dSAABEJAUAQJRz9dHUqVPd+Ec7Nz9MTS720blvjlZzk9WRtGvn570OHfxD4I1X253Vot/Ma9Y58cQT3bHePptZ0otI1PlS++Udl4MHD7pjvevITG+bdz7VWFW/n0JdZ/v373fjzfNEHYk61+pa8vZbnWt1fx3Ni6Q+Sm23d0zM/G1Tx0xdKyeddFJmTJ1rdZ2p/f7ou1aOZtm5TE3CkwIAICIpAAAikgIAICIpAAAikgIAICIpAAAikgIAIMq5T0HV3qbUxata55S6efXiDrXd3viGhoakZXvvUa6rq0tadkrNvTpm6nzV1NRkxoqKityxF154oRtvfgl8loKCgsxYdXW1O3bbtm1u3HupUNa7hJupt4qpY+7df+p93KqnxesdUdeZuha8nhV1/6jtVuv2vhfUWMX7TlLflSresWPHYx6vvitzwZMCACAiKQAAIpICACAiKQAAIpICACAiKQAAopxLUtUUul4JZGrJqSrXU9Mxp0iZfldt9759+zJj6pioY6pKUr1yQLVfPXv2dOPeNOtf+MIXkpatyvm867Q1yvWyVFVVufEVK1a48ddff92Nr1279pjXnZeX58a9Y6auI3WteKXVatnqGlf3V8r5Vt93HrXdamrslOn8WwNPCgCAiKQAAIhICgCAiKQAAIhICgCAiKQAAIhICgCAKOc+BdUL4NXOpkzjnMu6vXplVdObUvOraplTpvZtbGx0x6paZm/6ajO/dn3y5Mnu2OLiYjfuTY+t6tpVbXl9fb0bV9NIpzhw4EBmTPVXXHzxxUlxb+rtJUuWuGNffPFFN+7VzategJT+JSV1enjv/kvtffK2TS1bacvvpJzWn7wEAMBfDZICACAiKQAAIpICACAiKQAAIpICACAiKQAAopz7FNqy3l9RtetezX7q3ORe3a+qR1Z11t62qe3yaubNzM444ww3fuutt2bGRowY4Y5V+9XU1JQZU/ul6sM7derkxisrKzNja9ascceq/SooKMiMqT4Fb6yZWZcuXdz4oEGDMmOzZ892x3bs2NGNL168ODOmjreqi/d6ILzrxKxt33+hlq32y7v3U3s7UrTGMeNJAQAQkRQAABFJAQAQkRQAABFJAQAQkRQAABFJAQAQ5dyncNJJJ7nxlPnFU/oQ1Hg1VvHq5tV2q/nevV4Dr77bzGz48OFu/M4773Tj3jsP1PlS73rw9lvt1xNPPOHG1bsBxo4dmxkbM2aMO/bcc8914967GtR+qWOqrlPvmKuxs2bNcuN//OMfM2Pr1q1zx6r+ipTtVlS9v3d/poxVUnsFUt5RQZ8CAKBVkRQAABFJAQAQkRQAABFJAQAQkRQAAFGrlaR65ZVqSmIltfTTo8q/vHhq+Vf37t2Peezf//3fu3Gv5NTMLxVU+5UynbI63ueff74bHzBggBufMGFCZix1GnWvPFlNA62W3dDQ4Ma9kteUKdrNzK655prM2Ny5c92xar+9a0VNk546jbondap/75iq8mS1bnX/efGU78JmPCkAACKSAgAgIikAACKSAgAgIikAACKSAgAgIikAAKJW61Noy3p+Vdvu1WmrmmA1pbG3blVHrY6ZV+N96aWXumPPOOMMN66mt/aoY5bSd6LGnn766Ulx75iqc61q7jt27JgZS50GWtW2e9umatPVMfemDP/0pz/tjn3llVfcuLdf6nsh5TtHLT9lOn4zf7/Udqf2y3hx+hQAAK2KpAAAiEgKAICIpAAAiEgKAICIpAAAiEgKAIAo5+JqVVubMoe+9y4GM117mzLXvOo18LZd1ROr/c7Pz8+Mee8FMDOrr69340pbzs/vHdOU93LkIqUnxutDMDPbsWNHZmz16tXuWNUDMXToUDfu9aWofVb9GZ6ZM2e68TVr1rjxtrwWVG9HirZ8R0tKb5SScq6b8aQAAIhICgCAiKQAAIhICgCAiKQAAIhICgCAKOeSVFWm6MVTy6RSpmpOXXfK9LuqbHTMmDGZscLCQndsyjTPiipxTCkhbmhocMeq7Vb77ZUp7t+/3x374IMPuvEf/ehHmbGqqip3rNruzp07u3GvJPUrX/mKO3bGjBlu3DsugwYNcsf+7d/+rRt/4YUXMmOdOnVyx6qyUHWdeuNTy0a9uDrXqaXs3n6rZeeCJwUAQERSAABEJAUAQERSAABEJAUAQERSAABEJAUAQJRzn0JjY6Mb9+p2U6eKVfXIXh9DW06dreqRu3fv7sb/5m/+JjNWU1Pjju3SpYsbV9MS19XVZcbUlMQpUzWrZaf2X3hTWE+fPt0dW1JS4sa9vhR1HSmqf+PNN9/MjH3xi190x3q9AmZm8+bNy4yp3g7vGjYz+81vfpMZU308KdP1m/nnRC1bXeMp01unjFWYOhsA0KpICgCAiKQAAIhICgCAiKQAAIhICgCAiKQAAIhy7lNQddQpVE2w0pY9El6fg6pNHzZsmBsvKCjIjFVXV7tjU/oQzPx511WvgOr98N4NkPpegVWrVrnxyZMnZ8bUOw/U/P7eeyTU3P/qmKXMg6+u8Z/85Cdu3OsX+Nd//Vd3rOrFGTx4cGZs7dq17ti8vDw3rvbb6+VR50N9J3l9DqoXJ7VHojV6ETw8KQAAIpICACAiKQAAIpICACAiKQAAIpICACDKuSRVlUGllJW25TS1qev2Sj9VGaEqSfVKHFXpppp2WJVIeiWrqhSwW7dubtzbdjX1dWlpqRufMWOGG6+oqMiMqZJTVWLsHVN1jaoyRVUi6d1/6lwrTz/9dGZs0qRJ7tiZM2e6ce8e2LBhgzs2tTTTuw7Vvavi3nWsysXVslO+S1vju5InBQBARFIAAEQkBQBARFIAAEQkBQBARFIAAEQkBQBAlHOfQlvWzqbW1nrbpqapTZnGVtWee9MGm/m16aoPQa1b1dz37NkzM6bqrBsbG4953Wq7br31Vje+detWN+5Nl6zq2lV/hnctqNpzrycll3jK9PApUy1/61vfcuPXXnutG+/Xr19mTN17qf0X3nj1fabuLy+uxqb2KaT0y+SCJwUAQERSAABEJAUAQERSAABEJAUAQERSAABEJAUAQNRqfQop9bFq2Sru1f2mzpvurbtz587u2JUrV7rxESNGZMZOPfVUd2xDQ4MbV+8t8GrX1bsc1LoLCwszY88884w7dtGiRW68a9eubtyrfVfvU1BxVVfvUb0dqi/FOyfV1dXuWLXd3r27c+dOd+z8+fPd+Omnn54ZU30I6jpT967XE9OW7zxI/c5Rca8PIqUnJa4/eQkAgL8aJAUAQERSAABEJAUAQERSAABEJAUAQERSAABEx154fRTasg9BxVWNtlq2V0utxtbU1Ljxt956KzPWt29fd6zXC2BmVlRU5Ma9unlVH67eO/Dee+9lxu699153rDpfqjfEe59Cr1693LGqt8N7/4WquU+tTffOieqBUHHvuIwePdodW1dX58Y3bNiQGVN9IapfxjsfZmk1+63xXoIsKd85uYxPxZMCACAiKQAAIpICACAiKQAAIpICACAiKQAAopxLUlV5WMr01ap0TMVT1q3Kv7x119bWumP379/vxi+++OLM2NKlS92xq1evduM333yzG/em7e7WrZs7tqKiwo1/+ctfzoxt3brVHaumDFdTHntUmaEqd/WmLPZiZnpqbDX9tSc/P9+Nq9LP4cOHZ8ZUafSQIUPc+MaNGzNj+/btc8eq86HOp1fenDrFtCqj96jtVnFVipuKJwUAQERSAABEJAUAQERSAABEJAUAQERSAABEJAUAQJRzn4Kqs/ak9iGoulyvHlnVtav6ci+u6qzVdnfv3j0z9sYbb7hj1fn4z//8Tzfu1a5700+bmb322mtufM2aNZmx3r17u2PV+VDTW3u9I+Xl5e7YAwcOuPGRI0dmxtT58KYTN9P75dWuq/06/fTT3bg3xbu6fw4ePOjGvf1S07vv2bPHjXft2tWNe9umxqr99u4fdS5Tp772vi9bY8pvnhQAABFJAQAQkRQAABFJAQAQkRQAABFJAQAQkRQAAFHOfQqqJt+rnVX136rWWdXeenObq5phVRfvqaurc+PnnnuuG/fmmlfvapg0aZIbV/O9b9u2LTO2adMmd6wyYMCAzJjq3VA9KyUlJW7cqy/v2bOnO1a9/8KLq3cWqLr3/v37u/HGxsbMmNcXYqb7Aby+FHV/qHt38ODBmTH1Dont27e7cdVPo+79FN79pd7Roq4F9X1HnwIA4GNDUgAARCQFAEBEUgAARCQFAEBEUgAARDmXpKrpXr3SNFW21tTU5MZVmVXKVLSqRNLjlQma6dI0r+TuE5/4hDu2sLDQje/du9eNDxkyJDOWl5fnjvWmKjcz69y5c2bMmy7czKyhocGNe9M8m/nbnlqe7F1nqtxVlWVXVFS48b59+2bGPv/5z7tjTz31VDfuldOmTmXulT6vX7/eHavKqlVJuDc9tvpOSSntVNutlq2+N7zlp07LbcaTAgDgQ0gKAICIpAAAiEgKAICIpAAAiEgKAICIpAAAiHLuU1D15V7NsJoOWUmp61U19SlxVZs+fPhwN+71OfTo0cMdq3o/FK/+/OSTT3bHqmmivWtB9SGUl5e78VGjRrlxr+dFHTO1XwUFBZkxdcxOOeUUN676Srx7KD8/3x2rrvFu3bplxlQPkYqnSJ1S3+sNUf0XbdnHoI6ZOl8p03bngicFAEBEUgAARCQFAEBEUgAARCQFAEBEUgAARCQFAECUc5+CV8usqLnkVR+Dqgn26npVPbKqCfZqpXv16uWOXbp0qRsvKirKjHlzwZvpueS9dxqY+T0S6n0KXr2+mX8+d+/e7Y5VddZqvnjvWkupazfzt01dZ+p8qmPq1aardavz6V0Lqf0w3vlSvR2qd0O9t8A7LuqYKep7w6OuQ/V96O13Sv9EM54UAAARSQEAEJEUAAARSQEAEJEUAAARSQEAEJEUAABRq71PwautVfXfqbya4dT3KXg1wWpedFWbfujQocyYeu+A2m71boD6+vpjXvZJJ53kxr3zrZbdt2/fY162mX8dqvOVcp0WFha6cVUXr7bN65FQPUTeuVbrVn0jXo+DmX8dduzY8Zi3y0y/z8S7d1O/F7xtb8vvHLPWeWeChycFAEBEUgAARCQFAEBEUgAARCQFAEBEUgAARDmXpKryMS+uyiNVCZbiTc+rplpWca98TJVmqpI5r2R127Zt7thPfepTblxNoeudE1Waqaa/TpmWWx1TdS15U4rX1ta6Y3fs2OHGq6urM2PqeO/Zs8eNq2M+bNiwzFhqebI3PbaaxlndP17ZdWVlpTtWXQup3xseVfbpHXM1Vm23OqZtud9mPCkAAD6EpAAAiEgKAICIpAAAiEgKAICIpAAAiEgKAIAo5z4FVRvr9Sl07tw5admqBtyrC1Y13Kqm2Nv2lFpmFS8qKnLHqlpmNaWx1yOhxqqaei/u1cSbmeXn57txdS1500R7PQxmZmVlZW7cO9+qr0RdC6qnxZt6W50v1WPkXQvqmKn98qaAr6qqcseqPgV1LXn3iBqr7m3vGk/9Xkjpc1DfC7ngSQEAEJEUAAARSQEAEJEUAAARSQEAEJEUAAARSQEAEOXcp6Dqw71eAlUTrPoUUuZ09+q7zXTNsDf/vxqr9qtLly6ZMVW3rtat5qr39iu1b8Q75up8qHV78/Or5atjOmrUKDe+b9++zNiuXbvcsQMGDHDjp5xyihv36uLVtaDuP2+8qntX9+aWLVsyY6oHQvWsNDU1uXFv21J6HMz861RdwynbrahrIRc8KQAAIpICACAiKQAAIpICACAiKQAAIpICACDKuX5JTb/rlVGllmCllI+p6XdViaQX79GjhztWlW56ZYaqHE9ttzpfFRUVmTGvVNZMn49OnTplxtQxU9MGe1Mxm/klq+qYde/e3Y17215QUOCOVWWK6ph6JcTqmKjySnWPeNR2e/eAukZTp7f2Sl7VtaC+k1Kmr06d3trbb3Wd5YInBQBARFIAAEQkBQBARFIAAEQkBQBARFIAAEQkBQBAlHOfgpqS1at19urWc6H6HLza3JTtNvPrw1Wts+pTaGxszIypqZgVdcxqa2szY+Xl5e5YdT69PgdVe67qw1OmK/emvjYz27hxoxtP6YFQ/RnqmHvHbejQoe7Y/v37u3Gv7j1l2npF9Rmo6fq9+8fMv07VFOxqv9W97VG9BClx+hQAAK2KpAAAiEgKAICIpAAAiEgKAICIpAAAiEgKAIAo5z4FVbfr1Ryr+flVr0Bbzm2uaqW9WmdVq6xq6r11V1dXu2Pr6+uT1q3Ge1RNvveeCHW81XarY15VVZUZ27ZtmztW7dfpp5+eGVP7pd63oN4t4PWdqPvHe3eGmX9/qbr3mpoaN+7dP0VFRe7YlGNi5t/7ar9SvjfU+Uh9n4K3/JR3YzTjSQEAEJEUAAARSQEAEJEUAAARSQEAEJEUAAARSQEAEOXcp7B9+/ZjXklqTXBrzBHeFtR2p9Qjq/nelZT3SHh9Bma6Ptwbn1p7rvoUvNr33r17u2OVsrKyzNj+/fvdsapXQL07wNsvVZvetWtXN+5tuzpfar+9fhi1XWq/1LXi9RKo6yjlfQqp72pQ33fe/ZXynodmPCkAACKSAgAgIikAACKSAgAgIikAACKSAgAgyrkk9ZVXXnHjKaVQatphFfdKuFJLOz1quw4ePOjGU6b8ViWnqsRx2LBhmTE1zbNSV1eXGVPXSeq0w165n7oWVNmoV56pyl3V9PFqv7x1e8fbTJeNetdSY2OjO1aVT1ZWVmbGdu3a5Y71pkE3M8vPz3fj3rWgjndKyaoqOVVSSt1bo3yfJwUAQERSAABEJAUAQERSAABEJAUAQERSAABEJAUAQHSCmeXUYJCXl+fGvZp8VR+uamtT+hRSpsBVVK+AmoI6Req6TzvttMzY2LFj3bEnnniiG/fOV8q5NEvrc+jUqZM7tlevXm7c2+/U6ZJVbbq3X14vgJneNq+nRfUp9OzZ04174z/5yU+6YxcvXuzGH3nkETferVu3zFhq/5J3HaprNHV665R1q+nGzXhSAAB8CEkBABCRFAAAEUkBABCRFAAAEUkBABCRFAAAUc7vU5gyZYob9+pfGxoa3LGqhlvVtnu1uan1yN661dz/udQEZ1HbrebQV+9y8I6Z6hVQ++Vtm6rHV70Ear+8dweo+ffV/P01NTWZsdraWndsfX29G0/poVDvzlB9Jd62qf1S/TILFy7MjF133XXu2MmTJ7vx8vJyN/7b3/42M6beGaLugZT3FqheAnXve99Jqq+ktLTUjZvxpAAA+BCSAgAgIikAACKSAgAgIikAACKSAgAgyrkkdcyYMW7cK4VSZVKqBEuVMXolrarcVenYsWNmTG2XN9bML69UJaeKKq/0qPJIVWLsrVuda1UCqc6nt21q3fv27XPjXrmrKtNV14o6314ZoipJVeWwe/fuzYwVFhYe81gzs8suuywz1qdPH3esd7zNzL75zW+68QceeCAzVl1d7Y7t3r27G/euM3Xfp5TYq/HqOlqwYIEbN+NJAQDwISQFAEBEUgAARCQFAEBEUgAARCQFAEBEUgAARDn3KeTl5blxb3peNXVvyhTTiqprV1PgejXBqdNAe9umaplVPX+3bt3cuFfPPGDAgKR1e/0Aqq49dRp1bypnVcOtejvUuj2qdl3VxXfp0iUzpqYTV/vt3QPq/lD1/jNmzMiMpd73/fv3d+Nz5szJjD366KPuWHUdev0bqful+k685avrKBc8KQAAIpICACAiKQAAIpICACAiKQAAIpICACAiKQAAopz7FBSvZl/V83u15WZ6fnE1T34Kr15Z9V+o7fL2S9XEq2OqeHXv06ZNc8e+9tprbvz999/PjBUVFblj1bsaVE2+10+jeiTy8/Pd+IEDBzJj3vE0M+vatasbV+NPOumkzJh674B6n0LPnj0zY++++647dsiQIW78k5/8ZGZMvWcl9f7y+m0uvfRSd+ySJUvcuHd/pr4vQfF6R1K/F8x4UgAAfAhJAQAQkRQAABFJAQAQkRQAABFJAQAQ5VySqsqsvDIpVYKlygxV6ZkXV+tW8ZTpktW0w165q1f+aKan11XTQI8bNy4z1rdvX3esOmbetqnySa/00kwfU6/MUY1V+6VKp9tSRUVFZkxNja2mUy4rK8uMbdmyxR07d+5cN+6VGKvjqcor1fTW3vJHjx7tjn3jjTfceHl5eWZMlR+r60zd+175cmVlpTs2FzwpAAAikgIAICIpAAAikgIAICIpAAAikgIAICIpAACinAuvVY13ynSuqfXIHtXjoJatpu/1pPQ4qBpuNR1y79693fgll1ySGdu4caM79gc/+IEbnzhxYmYspc/AzKypqemY4+p8qHr/lGtcLVv1lXjL79Spkzt2165dbvw3v/lNZuzxxx93x6qeFu86Vfdm6pT63rpVn09xcbEbX758eWZs/fr17lh1DavvnJRrPBc8KQAAIpICACAiKQAAIpICACAiKQAAIpICACAiKQAAopz7FFRNsEfVpqt65JT3Eqg+BLVfbfmeCK/2XNW9K+PHj3fj3pzvS5cudce++uqrbnzUqFGZsfz8fHdsXl6eG1fj33///cyY6gVQ16F3Lam+EXWtqF4Dr8+hpKTEHbthwwY3fvnll2fGrrzySndsTU2NG/eod2eonhV1j3Ts2PGYl11YWOjGv/CFL2TGvOvfzGzlypVufNOmTW7ceydJa7zzgycFAEBEUgAARCQFAEBEUgAARCQFAEBEUgAARCQFAECUXtT6P7x6/tTaWTVHeMo896p+3Ft3Sl27Gq/mXB88eLAbv+CCC9x4aWlpZmzt2rXuWMWbT37KlCnu2Nra2qR1FxQUHPNYda14te3qWlB18Vu2bHHj3jsu1DFT7zy47777MmPqnQcq7r23QB0Tdd+r+yvlfKlj6n3n9O/f3x07cOBAN759+3Y3vmLFiszYm2++6Y7NBU8KAICIpAAAiEgKAICIpAAAiEgKAICIpAAAiHKuFVUlXN7UwWqKXCVlGmk1VpXUeSWrqmROxQ8cOJAZO/HEE92xkydPduNq2u5169ZlxlR5pNovb2pgNa1wz5493bjaL+9a86YLN9PTV7/33nuZsT/+8Y/u2M2bN7vxvXv3unHPmWee6cZvu+02N37aaadlxvbt2+eO9aanNvPPlyopVdT3irf8hoYGd6y6Frzx3n1tpu+ffv36uXFvOvMxY8a4Yx966CE3bsaTAgDgQ0gKAICIpAAAiEgKAICIpAAAiEgKAICIpAAAiHLuU1C1t94UuWoaaG8aWjNds59S75wyvbXXm2Gm98uryVf1/H369HHjavpdL75jxw53rOrt2L9/f2bskUcecceqmnvVx+DVeKu69q1bt7rx119/PTNWVVXljlXXmar396aBnjZtmjv2S1/6khvfvXt3Zkz1J6k+oJQeI0XdXynU953Xv6Sm41dx9X3pXceDBg1yx+aCJwUAQERSAABEJAUAQERSAABEJAUAQERSAABEJAUAQJRzn0LKOxFUrbKqN1Zzn3vLV9utau69+eCHDRvmjh0xYoQb92rqvb4Ps7Q6ajOzysrKzFhZWZk7VvHWrXo7VqxYkbRubx581SugroWUfpiUd2uYmU2cODEz9nd/93fuWK9vxMzvRUh5Z4Fatrrv1feGusa93g61Xyn9GeqdH6m9Hd5+qe+NXPCkAACISAoAgIikAACISAoAgIikAACISAoAgCjnklRVZuWVcKkSK1WulzKtcHV1tTu2sLDQjX/605/OjA0ePNgdq/bLmyLX2yczXVKnjrk3PbYqAVa8daeUMJrp69DbdnVM1LZ5JZSqPLKoqMiNT58+3Y3fc889mbGCggJ3bEVFhRtXx9yjykq9eyDleJvpY+6NV9NTq2PiLVuVNivqVQHe8lXJdy54UgAARCQFAEBEUgAARCQFAEBEUgAARCQFAEBEUgAARDkXKKdM96rGqmmDVd18Xl5eZmzo0KHu2LFjx7rxrl27ZsZUL4GqV/aOi6rBTp0625v2W/VXKF4Nt+ozUMdMbVtKjbhatndMBw0a5I5duHChG1c1+W+//XZm7KyzznLHdu/e3Y175yR12vuU/iXVx1BXV+fGveWr7U65d1WPg9ovdW+n3p8KTwoAgIikAACISAoAgIikAACISAoAgIikAACISAoAgCjnPgVV1+vV1qq5y9V88MOHD3fjI0aMyIx5fQZmuh7Zm5+8U6dO7ljF679Ifa/AySef7ManTp2aGVu8eLE79pVXXnHjXj1/ap+BqvFOmb9fxb157r/xjW+4Y9U98PLLL7vx/Pz8zNjWrVvdseeff74b93pW1LtMVD+Md52qa0HV66s+BdWf4UnpoUjpdzHT14r3LhV1DeeCJwUAQERSAABEJAUAQERSAABEJAUAQERSAABEJAUAQJRzn4KqGfbiZ599tjt2zJgxblz1GqTU5qbUBKteAdXb4dWAqxpstW6vpt7Mr3tfsmSJO/b3v/+9G//qV7+aGfvDH/7gjlVUjbfX56DOh6pNv+OOOzJj48ePd8fOnz/fjffp08eNe30ntbW17th169a58bKysmPeLu86MvOv8c6dO7tj1ftK1PnyrhV1HaVQy1bXobp3U9adC54UAAARSQEAEJEUAAARSQEAEJEUAAARSQEAEOVcklpdXe3Gx44dmxmbOHGiO1aVaKmyUW+aaTUVsyr/8rZNbXdbUvuVUvr5iU98wo1feOGFbvyFF17IjF199dXu2KVLl7pxNaW4V5KnjtnnPvc5Nz579uzM2KpVq9yxVVVVbnzSpEluvLKyMjM2aNAgd2zKVM179uxxx+7evduNe2WjamprVe5aWFjoxr3zraa3VlQ5bIqU6eNTylmb8aQAAIhICgCAiKQAAIhICgCAiKQAAIhICgCAiKQAAIhOMLO2m0MWAPAXhScFAEBEUgAARCQFAEBEUgAARCQFAEBEUgAARCQFAEBEUgAARCQFAED0/wCNf8FjG9SUBQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models/emotion_custom_cnn.h5. Creating and training a new model...\n",
      "Patches shape: (None, 48, 48, 9)\n",
      "Reshaped patches shape: (None, 2304, 3, 3, 1)\n",
      "Spiral patches shape: (None, 2226, 3, 3, 1)\n",
      "Convolution result shape: (None, 2226, 3, 32)\n",
      "Patches shape: (None, 24, 24, 288)\n",
      "Reshaped patches shape: (None, 576, 3, 3, 32)\n",
      "Spiral patches shape: (None, 540, 3, 3, 32)\n",
      "Convolution result shape: (None, 540, 3, 64)\n",
      "Patches shape: (None, 12, 12, 576)\n",
      "Reshaped patches shape: (None, 144, 3, 3, 64)\n",
      "Spiral patches shape: (None, 128, 3, 3, 64)\n",
      "Convolution result shape: (None, 128, 3, 128)\n",
      "Model layers and output shapes:\n",
      "Layer Name: spiral_conv2d, Output Shape: (None, 48, 48, 32)\n",
      "Layer Name: max_pooling2d, Output Shape: (None, 24, 24, 32)\n",
      "Layer Name: spiral_conv2d_1, Output Shape: (None, 24, 24, 64)\n",
      "Layer Name: max_pooling2d_1, Output Shape: (None, 12, 12, 64)\n",
      "Layer Name: spiral_conv2d_2, Output Shape: (None, 12, 12, 128)\n",
      "Layer Name: max_pooling2d_2, Output Shape: (None, 6, 6, 128)\n",
      "Layer Name: flatten, Output Shape: (None, 4608)\n",
      "Layer Name: dense, Output Shape: (None, 128)\n",
      "Layer Name: dense_1, Output Shape: (None, 7)\n",
      "Epoch 1/10\n",
      "Patches shape: (None, 48, 48, 9)\n",
      "Reshaped patches shape: (None, 2304, 3, 3, 1)\n",
      "Spiral patches shape: (None, 2226, 3, 3, 1)\n",
      "Convolution result shape: (None, 2226, 3, 32)\n",
      "Patches shape: (None, 24, 24, 288)\n",
      "Reshaped patches shape: (None, 576, 3, 3, 32)\n",
      "Spiral patches shape: (None, 540, 3, 3, 32)\n",
      "Convolution result shape: (None, 540, 3, 64)\n",
      "Patches shape: (None, 12, 12, 576)\n",
      "Reshaped patches shape: (None, 144, 3, 3, 64)\n",
      "Spiral patches shape: (None, 128, 3, 3, 64)\n",
      "Convolution result shape: (None, 128, 3, 128)\n",
      "Patches shape: (None, 48, 48, 9)\n",
      "Reshaped patches shape: (None, 2304, 3, 3, 1)\n",
      "Spiral patches shape: (None, 2226, 3, 3, 1)\n",
      "Convolution result shape: (None, 2226, 3, 32)\n",
      "Patches shape: (None, 24, 24, 288)\n",
      "Reshaped patches shape: (None, 576, 3, 3, 32)\n",
      "Spiral patches shape: (None, 540, 3, 3, 32)\n",
      "Convolution result shape: (None, 540, 3, 64)\n",
      "Patches shape: (None, 12, 12, 576)\n",
      "Reshaped patches shape: (None, 144, 3, 3, 64)\n",
      "Spiral patches shape: (None, 128, 3, 3, 64)\n",
      "Convolution result shape: (None, 128, 3, 128)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/spiral_conv2d/Reshape_1' defined at (most recent call last):\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\1357086569.py\", line 6, in <module>\n      emotion_system.run()\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\3277853973.py\", line 30, in run\n      self.emotion_cnn.train_model(\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\2345869713.py\", line 35, in train_model\n      history = self.model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=epochs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\3083889868.py\", line 59, in call\n      outputs = tf.reshape(conv_result, [batch_size, height, width, self.filters])\nNode: 'sequential/spiral_conv2d/Reshape_1'\nDetected at node 'sequential/spiral_conv2d/Reshape_1' defined at (most recent call last):\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\1357086569.py\", line 6, in <module>\n      emotion_system.run()\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\3277853973.py\", line 30, in run\n      self.emotion_cnn.train_model(\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\2345869713.py\", line 35, in train_model\n      history = self.model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=epochs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\3083889868.py\", line 59, in call\n      outputs = tf.reshape(conv_result, [batch_size, height, width, self.filters])\nNode: 'sequential/spiral_conv2d/Reshape_1'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 6838272 values, but the requested shape has 2359296\n\t [[{{node sequential/spiral_conv2d/Reshape_1}}]]\n\t [[gradient_tape/sequential/spiral_conv2d_2/Reshape_4/_60]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 6838272 values, but the requested shape has 2359296\n\t [[{{node sequential/spiral_conv2d/Reshape_1}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1893]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m      5\u001b[0m emotion_system \u001b[38;5;241m=\u001b[39m EmotionDetectionSystem(dataset_path, input_shape, num_classes)\n\u001b[1;32m----> 6\u001b[0m \u001b[43memotion_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m, in \u001b[0;36mEmotionDetectionSystem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotion_cnn\u001b[38;5;241m.\u001b[39mbuild_model()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotion_cnn\u001b[38;5;241m.\u001b[39mcompile_model()\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memotion_cnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_preprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_preprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_preprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_preprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotion_cnn\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path)\n",
      "Cell \u001b[1;32mIn[5], line 35\u001b[0m, in \u001b[0;36mEmotionCNN.train_model\u001b[1;34m(self, train_data, train_labels, val_data, val_labels, epochs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_data, train_labels, val_data, val_labels, epochs):\n\u001b[1;32m---> 35\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/spiral_conv2d/Reshape_1' defined at (most recent call last):\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\1357086569.py\", line 6, in <module>\n      emotion_system.run()\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\3277853973.py\", line 30, in run\n      self.emotion_cnn.train_model(\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\2345869713.py\", line 35, in train_model\n      history = self.model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=epochs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\3083889868.py\", line 59, in call\n      outputs = tf.reshape(conv_result, [batch_size, height, width, self.filters])\nNode: 'sequential/spiral_conv2d/Reshape_1'\nDetected at node 'sequential/spiral_conv2d/Reshape_1' defined at (most recent call last):\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\1357086569.py\", line 6, in <module>\n      emotion_system.run()\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\3277853973.py\", line 30, in run\n      self.emotion_cnn.train_model(\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\2345869713.py\", line 35, in train_model\n      history = self.model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=epochs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14700\\3083889868.py\", line 59, in call\n      outputs = tf.reshape(conv_result, [batch_size, height, width, self.filters])\nNode: 'sequential/spiral_conv2d/Reshape_1'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 6838272 values, but the requested shape has 2359296\n\t [[{{node sequential/spiral_conv2d/Reshape_1}}]]\n\t [[gradient_tape/sequential/spiral_conv2d_2/Reshape_4/_60]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 6838272 values, but the requested shape has 2359296\n\t [[{{node sequential/spiral_conv2d/Reshape_1}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1893]"
     ]
    }
   ],
   "source": [
    "# Run the system\n",
    "dataset_path = \"fer2013_data\"\n",
    "input_shape = (48, 48, 1)\n",
    "num_classes = 7\n",
    "emotion_system = EmotionDetectionSystem(dataset_path, input_shape, num_classes)\n",
    "emotion_system.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
